{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9795944,"sourceType":"datasetVersion","datasetId":6003234}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-03T16:56:33.693995Z","iopub.execute_input":"2024-11-03T16:56:33.694381Z","iopub.status.idle":"2024-11-03T16:56:33.708325Z","shell.execute_reply.started":"2024-11-03T16:56:33.694346Z","shell.execute_reply":"2024-11-03T16:56:33.707412Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/cve-dataset-with-embedding/merged_cve_data.csv\n","output_type":"stream"}],"execution_count":92},{"cell_type":"code","source":"! pip install xgboost\n!pip install lightgbm catboost torch torchvision torchaudio\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T15:43:10.053389Z","iopub.execute_input":"2024-11-03T15:43:10.054054Z","iopub.status.idle":"2024-11-03T15:43:34.116193Z","shell.execute_reply.started":"2024-11-03T15:43:10.054013Z","shell.execute_reply":"2024-11-03T15:43:34.115118Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: xgboost in /opt/conda/lib/python3.10/site-packages (2.0.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from xgboost) (1.26.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from xgboost) (1.14.1)\nRequirement already satisfied: lightgbm in /opt/conda/lib/python3.10/site-packages (4.2.0)\nRequirement already satisfied: catboost in /opt/conda/lib/python3.10/site-packages (1.2.7)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.19.0)\nRequirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from lightgbm) (1.26.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from lightgbm) (1.14.1)\nRequirement already satisfied: graphviz in /opt/conda/lib/python3.10/site-packages (from catboost) (0.20.3)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from catboost) (3.7.5)\nRequirement already satisfied: pandas>=0.24 in /opt/conda/lib/python3.10/site-packages (from catboost) (2.2.2)\nRequirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (from catboost) (5.22.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from catboost) (1.16.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (10.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2024.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (3.1.2)\nRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly->catboost) (8.3.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/cve-dataset-with-embedding/merged_cve_data.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T17:23:54.493242Z","iopub.execute_input":"2024-11-03T17:23:54.494152Z","iopub.status.idle":"2024-11-03T17:24:12.013969Z","shell.execute_reply.started":"2024-11-03T17:23:54.494107Z","shell.execute_reply":"2024-11-03T17:24:12.013020Z"}},"outputs":[],"execution_count":117},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T17:24:12.015975Z","iopub.execute_input":"2024-11-03T17:24:12.016650Z","iopub.status.idle":"2024-11-03T17:24:12.110161Z","shell.execute_reply.started":"2024-11-03T17:24:12.016602Z","shell.execute_reply":"2024-11-03T17:24:12.109219Z"}},"outputs":[{"execution_count":118,"output_type":"execute_result","data":{"text/plain":"               CVE_ID                    ASSIGNER             Published_Date  \\\n0       CVE-2011-0199  product-security@apple.com  2011-06-24 20:55:00+00:00   \n1       CVE-2011-0220  product-security@apple.com  2020-02-05 20:15:00+00:00   \n2       CVE-2011-0428               cve@mitre.org  2019-10-29 19:15:00+00:00   \n3       CVE-2011-0467       security@opentext.com  2018-06-07 21:29:00+00:00   \n4       CVE-2011-0469       security@opentext.com  2017-08-17 16:29:00+00:00   \n...               ...                         ...                        ...   \n107082  CVE-2008-7315               cve@mitre.org  2017-10-10 16:29:00+00:00   \n107083  CVE-2008-7316         security@debian.org  2016-05-02 10:59:00+00:00   \n107084  CVE-2008-7319               cve@mitre.org  2017-11-07 21:29:00+00:00   \n107085  CVE-2008-7320               cve@mitre.org  2018-11-18 19:29:00+00:00   \n107086  CVE-2008-7321               cve@mitre.org  2019-08-22 14:15:00+00:00   \n\n               Last_Modified_Date  Impact_Score Access_Vector  \\\n0       2024-02-09 03:18:00+00:00           3.6       NETWORK   \n1       2020-02-07 19:24:00+00:00           3.6         LOCAL   \n2       2019-11-01 14:55:00+00:00           2.7       NETWORK   \n3       2023-11-07 02:06:00+00:00           5.9       NETWORK   \n4       2023-11-07 02:06:00+00:00           5.9       NETWORK   \n...                           ...           ...           ...   \n107082  2017-11-03 17:15:00+00:00           5.9       NETWORK   \n107083  2016-05-06 00:54:00+00:00           3.6         LOCAL   \n107084  2017-11-29 15:49:00+00:00           5.9       NETWORK   \n107085  2024-08-07 12:15:00+00:00           5.9         LOCAL   \n107086  2019-08-23 19:44:00+00:00           2.7       NETWORK   \n\n       Access_Complexity                                     Configurations  \\\n0                 MEDIUM  ['cpe:2.3:o:apple:mac_os_x_server:*:*:*:*:*:*:...   \n1                    LOW        ['cpe:2.3:a:apple:bonjour:*:*:*:*:*:*:*:*']   \n2                 MEDIUM      ['cpe:2.3:a:ikiwiki:ikiwiki:*:*:*:*:*:*:*:*']   \n3                    LOW  ['cpe:2.3:a:suse:studio_onsite_appliance:*:*:*...   \n4                    LOW        ['cpe:2.3:o:suse:opensuse:-:*:*:*:*:*:*:*']   \n...                  ...                                                ...   \n107082               LOW  ['cpe:2.3:a:cpan:ui\\\\:\\\\:dialog:0.01:*:*:*:*:*...   \n107083               LOW   ['cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*']   \n107084               LOW  ['cpe:2.3:a:net-ping-external_project:net-ping...   \n107085               LOW       ['cpe:2.3:a:gnome:seahorse:*:*:*:*:*:*:*:*']   \n107086            MEDIUM  ['cpe:2.3:a:tubepress:tubepress:*:*:*:*:*:word...   \n\n                                           Reference_Data  Year  ...  \\\n0       ['http://support.apple.com/kb/HT4723', 'http:/...  2011  ...   \n1       ['https://opensource.apple.com/source/mDNSResp...  2020  ...   \n2       ['https://security-tracker.debian.org/tracker/...  2019  ...   \n3       ['https://bugzilla.suse.com/show_bug.cgi?id=67...  2018  ...   \n4       ['https://bugzilla.suse.com/show_bug.cgi?id=67...  2017  ...   \n...                                                   ...   ...  ...   \n107082  ['https://security-tracker.debian.org/tracker/...  2017  ...   \n107083  ['http://git.kernel.org/cgit/linux/kernel/git/...  2016  ...   \n107084  ['https://rt.cpan.org/Public/Bug/Display.html?...  2017  ...   \n107085  ['https://www.bountysource.com/issues/3849352-...  2018  ...   \n107086  ['https://wordpress.org/plugins/tubepress/#dev...  2019  ...   \n\n             759       760       761       762       763       764       765  \\\n0      -0.007224 -0.015303  0.056557 -0.039082  0.008622  0.022517 -0.040034   \n1       0.016330  0.049928  0.008830  0.000793  0.017700  0.028334  0.005227   \n2       0.016057 -0.002453  0.037362 -0.007217 -0.034629 -0.005441 -0.000510   \n3       0.023072 -0.052349  0.029655 -0.052779 -0.018734 -0.022419 -0.001663   \n4       0.008663  0.009789  0.012439 -0.032353  0.007584 -0.005330  0.010918   \n...          ...       ...       ...       ...       ...       ...       ...   \n107082  0.019123 -0.046788  0.001866  0.024574 -0.024319 -0.030054  0.025092   \n107083  0.014300 -0.012750 -0.036155 -0.043011  0.024458  0.012200 -0.009282   \n107084  0.034606 -0.056721 -0.028375 -0.023293 -0.014179 -0.005051 -0.029391   \n107085 -0.022035  0.005189 -0.003003  0.003738  0.012156 -0.027635 -0.001326   \n107086 -0.005189 -0.073709  0.005477  0.011733 -0.017345 -0.009489 -0.022760   \n\n             766       767                                        Description  \n0       0.014473  0.011391  The Certificate Trust Policy component in Appl...  \n1       0.049708 -0.015749  Apple Bonjour before 2011 allows a crash via a...  \n2      -0.015185 -0.025799  Cross Site Scripting (XSS) in ikiwiki before 3...  \n3       0.004668 -0.070693  A vulnerability in the listing of available so...  \n4      -0.033823  0.007783  Code injection in openSUSE when running some s...  \n...          ...       ...                                                ...  \n107082 -0.023828 -0.022433  UI-Dialog 1.09 and earlier allows remote attac...  \n107083  0.023590 -0.018185  mm/filemap.c in the Linux kernel before 2.6.25...  \n107084 -0.020186 -0.033210  The Net::Ping::External extension through 0.15...  \n107085  0.000663 -0.036381  GNOME Seahorse through 3.30 allows physically ...  \n107086  0.000676  0.032018  The tubepress plugin before 1.6.5 for WordPres...  \n\n[107087 rows x 784 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CVE_ID</th>\n      <th>ASSIGNER</th>\n      <th>Published_Date</th>\n      <th>Last_Modified_Date</th>\n      <th>Impact_Score</th>\n      <th>Access_Vector</th>\n      <th>Access_Complexity</th>\n      <th>Configurations</th>\n      <th>Reference_Data</th>\n      <th>Year</th>\n      <th>...</th>\n      <th>759</th>\n      <th>760</th>\n      <th>761</th>\n      <th>762</th>\n      <th>763</th>\n      <th>764</th>\n      <th>765</th>\n      <th>766</th>\n      <th>767</th>\n      <th>Description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CVE-2011-0199</td>\n      <td>product-security@apple.com</td>\n      <td>2011-06-24 20:55:00+00:00</td>\n      <td>2024-02-09 03:18:00+00:00</td>\n      <td>3.6</td>\n      <td>NETWORK</td>\n      <td>MEDIUM</td>\n      <td>['cpe:2.3:o:apple:mac_os_x_server:*:*:*:*:*:*:...</td>\n      <td>['http://support.apple.com/kb/HT4723', 'http:/...</td>\n      <td>2011</td>\n      <td>...</td>\n      <td>-0.007224</td>\n      <td>-0.015303</td>\n      <td>0.056557</td>\n      <td>-0.039082</td>\n      <td>0.008622</td>\n      <td>0.022517</td>\n      <td>-0.040034</td>\n      <td>0.014473</td>\n      <td>0.011391</td>\n      <td>The Certificate Trust Policy component in Appl...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CVE-2011-0220</td>\n      <td>product-security@apple.com</td>\n      <td>2020-02-05 20:15:00+00:00</td>\n      <td>2020-02-07 19:24:00+00:00</td>\n      <td>3.6</td>\n      <td>LOCAL</td>\n      <td>LOW</td>\n      <td>['cpe:2.3:a:apple:bonjour:*:*:*:*:*:*:*:*']</td>\n      <td>['https://opensource.apple.com/source/mDNSResp...</td>\n      <td>2020</td>\n      <td>...</td>\n      <td>0.016330</td>\n      <td>0.049928</td>\n      <td>0.008830</td>\n      <td>0.000793</td>\n      <td>0.017700</td>\n      <td>0.028334</td>\n      <td>0.005227</td>\n      <td>0.049708</td>\n      <td>-0.015749</td>\n      <td>Apple Bonjour before 2011 allows a crash via a...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CVE-2011-0428</td>\n      <td>cve@mitre.org</td>\n      <td>2019-10-29 19:15:00+00:00</td>\n      <td>2019-11-01 14:55:00+00:00</td>\n      <td>2.7</td>\n      <td>NETWORK</td>\n      <td>MEDIUM</td>\n      <td>['cpe:2.3:a:ikiwiki:ikiwiki:*:*:*:*:*:*:*:*']</td>\n      <td>['https://security-tracker.debian.org/tracker/...</td>\n      <td>2019</td>\n      <td>...</td>\n      <td>0.016057</td>\n      <td>-0.002453</td>\n      <td>0.037362</td>\n      <td>-0.007217</td>\n      <td>-0.034629</td>\n      <td>-0.005441</td>\n      <td>-0.000510</td>\n      <td>-0.015185</td>\n      <td>-0.025799</td>\n      <td>Cross Site Scripting (XSS) in ikiwiki before 3...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CVE-2011-0467</td>\n      <td>security@opentext.com</td>\n      <td>2018-06-07 21:29:00+00:00</td>\n      <td>2023-11-07 02:06:00+00:00</td>\n      <td>5.9</td>\n      <td>NETWORK</td>\n      <td>LOW</td>\n      <td>['cpe:2.3:a:suse:studio_onsite_appliance:*:*:*...</td>\n      <td>['https://bugzilla.suse.com/show_bug.cgi?id=67...</td>\n      <td>2018</td>\n      <td>...</td>\n      <td>0.023072</td>\n      <td>-0.052349</td>\n      <td>0.029655</td>\n      <td>-0.052779</td>\n      <td>-0.018734</td>\n      <td>-0.022419</td>\n      <td>-0.001663</td>\n      <td>0.004668</td>\n      <td>-0.070693</td>\n      <td>A vulnerability in the listing of available so...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CVE-2011-0469</td>\n      <td>security@opentext.com</td>\n      <td>2017-08-17 16:29:00+00:00</td>\n      <td>2023-11-07 02:06:00+00:00</td>\n      <td>5.9</td>\n      <td>NETWORK</td>\n      <td>LOW</td>\n      <td>['cpe:2.3:o:suse:opensuse:-:*:*:*:*:*:*:*']</td>\n      <td>['https://bugzilla.suse.com/show_bug.cgi?id=67...</td>\n      <td>2017</td>\n      <td>...</td>\n      <td>0.008663</td>\n      <td>0.009789</td>\n      <td>0.012439</td>\n      <td>-0.032353</td>\n      <td>0.007584</td>\n      <td>-0.005330</td>\n      <td>0.010918</td>\n      <td>-0.033823</td>\n      <td>0.007783</td>\n      <td>Code injection in openSUSE when running some s...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>107082</th>\n      <td>CVE-2008-7315</td>\n      <td>cve@mitre.org</td>\n      <td>2017-10-10 16:29:00+00:00</td>\n      <td>2017-11-03 17:15:00+00:00</td>\n      <td>5.9</td>\n      <td>NETWORK</td>\n      <td>LOW</td>\n      <td>['cpe:2.3:a:cpan:ui\\\\:\\\\:dialog:0.01:*:*:*:*:*...</td>\n      <td>['https://security-tracker.debian.org/tracker/...</td>\n      <td>2017</td>\n      <td>...</td>\n      <td>0.019123</td>\n      <td>-0.046788</td>\n      <td>0.001866</td>\n      <td>0.024574</td>\n      <td>-0.024319</td>\n      <td>-0.030054</td>\n      <td>0.025092</td>\n      <td>-0.023828</td>\n      <td>-0.022433</td>\n      <td>UI-Dialog 1.09 and earlier allows remote attac...</td>\n    </tr>\n    <tr>\n      <th>107083</th>\n      <td>CVE-2008-7316</td>\n      <td>security@debian.org</td>\n      <td>2016-05-02 10:59:00+00:00</td>\n      <td>2016-05-06 00:54:00+00:00</td>\n      <td>3.6</td>\n      <td>LOCAL</td>\n      <td>LOW</td>\n      <td>['cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*']</td>\n      <td>['http://git.kernel.org/cgit/linux/kernel/git/...</td>\n      <td>2016</td>\n      <td>...</td>\n      <td>0.014300</td>\n      <td>-0.012750</td>\n      <td>-0.036155</td>\n      <td>-0.043011</td>\n      <td>0.024458</td>\n      <td>0.012200</td>\n      <td>-0.009282</td>\n      <td>0.023590</td>\n      <td>-0.018185</td>\n      <td>mm/filemap.c in the Linux kernel before 2.6.25...</td>\n    </tr>\n    <tr>\n      <th>107084</th>\n      <td>CVE-2008-7319</td>\n      <td>cve@mitre.org</td>\n      <td>2017-11-07 21:29:00+00:00</td>\n      <td>2017-11-29 15:49:00+00:00</td>\n      <td>5.9</td>\n      <td>NETWORK</td>\n      <td>LOW</td>\n      <td>['cpe:2.3:a:net-ping-external_project:net-ping...</td>\n      <td>['https://rt.cpan.org/Public/Bug/Display.html?...</td>\n      <td>2017</td>\n      <td>...</td>\n      <td>0.034606</td>\n      <td>-0.056721</td>\n      <td>-0.028375</td>\n      <td>-0.023293</td>\n      <td>-0.014179</td>\n      <td>-0.005051</td>\n      <td>-0.029391</td>\n      <td>-0.020186</td>\n      <td>-0.033210</td>\n      <td>The Net::Ping::External extension through 0.15...</td>\n    </tr>\n    <tr>\n      <th>107085</th>\n      <td>CVE-2008-7320</td>\n      <td>cve@mitre.org</td>\n      <td>2018-11-18 19:29:00+00:00</td>\n      <td>2024-08-07 12:15:00+00:00</td>\n      <td>5.9</td>\n      <td>LOCAL</td>\n      <td>LOW</td>\n      <td>['cpe:2.3:a:gnome:seahorse:*:*:*:*:*:*:*:*']</td>\n      <td>['https://www.bountysource.com/issues/3849352-...</td>\n      <td>2018</td>\n      <td>...</td>\n      <td>-0.022035</td>\n      <td>0.005189</td>\n      <td>-0.003003</td>\n      <td>0.003738</td>\n      <td>0.012156</td>\n      <td>-0.027635</td>\n      <td>-0.001326</td>\n      <td>0.000663</td>\n      <td>-0.036381</td>\n      <td>GNOME Seahorse through 3.30 allows physically ...</td>\n    </tr>\n    <tr>\n      <th>107086</th>\n      <td>CVE-2008-7321</td>\n      <td>cve@mitre.org</td>\n      <td>2019-08-22 14:15:00+00:00</td>\n      <td>2019-08-23 19:44:00+00:00</td>\n      <td>2.7</td>\n      <td>NETWORK</td>\n      <td>MEDIUM</td>\n      <td>['cpe:2.3:a:tubepress:tubepress:*:*:*:*:*:word...</td>\n      <td>['https://wordpress.org/plugins/tubepress/#dev...</td>\n      <td>2019</td>\n      <td>...</td>\n      <td>-0.005189</td>\n      <td>-0.073709</td>\n      <td>0.005477</td>\n      <td>0.011733</td>\n      <td>-0.017345</td>\n      <td>-0.009489</td>\n      <td>-0.022760</td>\n      <td>0.000676</td>\n      <td>0.032018</td>\n      <td>The tubepress plugin before 1.6.5 for WordPres...</td>\n    </tr>\n  </tbody>\n</table>\n<p>107087 rows × 784 columns</p>\n</div>"},"metadata":{}}],"execution_count":118},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Impact_Score","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# Assuming 'df' is your DataFrame with all the columns\n# Define columns to exclude\ncolumns_to_exclude = [\n    'Impact_Score', 'CVE_ID', 'ASSIGNER', 'Description', \n    'Published_Date', 'Last_Modified_Date', \n    'Access_Vector', 'Access_Complexity', \n    'Configurations', 'Reference_Data',\n    'Year', 'Base_Score', 'Exploitability_Score', \n    'Confidentiality_Impact', 'Integrity_Impact', \n    'Availability_Impact'\n]\n\n# Separate the target variable\ny = df['Impact_Score']  # Your target variable\n\n# Select all columns except the excluded ones\nX = df.drop(columns=columns_to_exclude)\n\n# Check shapes\nprint(X.shape)  # Should show (n_samples, n_features) where n_features should only include your embedding columns\nprint(y.shape)  # Should show (n_samples,)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T15:44:13.978253Z","iopub.execute_input":"2024-11-03T15:44:13.978753Z","iopub.status.idle":"2024-11-03T15:44:14.170507Z","shell.execute_reply.started":"2024-11-03T15:44:13.978712Z","shell.execute_reply":"2024-11-03T15:44:14.169512Z"}},"outputs":[{"name":"stdout","text":"(107087, 768)\n(107087,)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import pandas as pd\nimport xgboost as xgb\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom sklearn.model_selection import train_test_split\n\n# Load your dataset\n# X, y = ... (Load your features and target variable)\n\n# Split the dataset\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train XGBoost Regressor with GPU\nxgb_regressor_gpu = xgb.XGBRegressor(tree_method='gpu_hist', gpu_id=0)\nxgb_regressor_gpu.fit(X_train, y_train)\n\n# Predict and evaluate XGBoost\ny_pred_xgb_gpu = xgb_regressor_gpu.predict(X_test)\nmse_xgb_gpu = mean_squared_error(y_test, y_pred_xgb_gpu)\nmae_xgb_gpu = mean_absolute_error(y_test, y_pred_xgb_gpu)\nr2_xgb_gpu = r2_score(y_test, y_pred_xgb_gpu)\n\nprint(\"XGBoost GPU Metrics:\")\nprint(f\"MSE: {mse_xgb_gpu:.4f}, MAE: {mae_xgb_gpu:.4f}, R²: {r2_xgb_gpu:.4f}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T15:44:14.508398Z","iopub.execute_input":"2024-11-03T15:44:14.509189Z","iopub.status.idle":"2024-11-03T15:44:25.485921Z","shell.execute_reply.started":"2024-11-03T15:44:14.509149Z","shell.execute_reply":"2024-11-03T15:44:25.484838Z"}},"outputs":[{"name":"stdout","text":"XGBoost GPU Metrics:\nMSE: 1.1454, MAE: 0.7909, R²: 0.4984\n\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\nimport pandas as pd\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom sklearn.model_selection import train_test_split\n\n# Load your dataset\n# X, y = ... (Load your features and target variable)\n\n# Split the dataset\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train LightGBM Regressor with GPU\nlgb_regressor_gpu = lgb.LGBMRegressor(device='gpu')\nlgb_regressor_gpu.fit(X_train, y_train)\n\n# Predict and evaluate LightGBM\ny_pred_lgb_gpu = lgb_regressor_gpu.predict(X_test)\nmse_lgb_gpu = mean_squared_error(y_test, y_pred_lgb_gpu)\nmae_lgb_gpu = mean_absolute_error(y_test, y_pred_lgb_gpu)\nr2_lgb_gpu = r2_score(y_test, y_pred_lgb_gpu)\n\nprint(\"LightGBM GPU Metrics:\")\nprint(f\"MSE: {mse_lgb_gpu:.4f}, MAE: {mae_lgb_gpu:.4f}, R²: {r2_lgb_gpu:.4f}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T15:45:18.234136Z","iopub.execute_input":"2024-11-03T15:45:18.235173Z","iopub.status.idle":"2024-11-03T15:45:39.699174Z","shell.execute_reply.started":"2024-11-03T15:45:18.235130Z","shell.execute_reply":"2024-11-03T15:45:39.698153Z"}},"outputs":[{"name":"stdout","text":"[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 195840\n[LightGBM] [Info] Number of data points in the train set: 85669, number of used features: 768\n[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 768 dense feature groups (62.75 MB) transferred to GPU in 0.050672 secs. 0 sparse feature groups\n[LightGBM] [Info] Start training from score 4.379723\nLightGBM GPU Metrics:\nMSE: 1.1747, MAE: 0.8198, R²: 0.4856\n\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import pickle\n# Save the trained model using pickle\nmodel_filename = 'impact_Score_xgb_regressor.pkl'\nwith open(model_filename, 'wb') as file:\n    pickle.dump(xgb_regressor_gpu, file)\n\nprint(f\"Model saved as {model_filename}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T15:46:01.218913Z","iopub.execute_input":"2024-11-03T15:46:01.219902Z","iopub.status.idle":"2024-11-03T15:46:01.241304Z","shell.execute_reply.started":"2024-11-03T15:46:01.219846Z","shell.execute_reply":"2024-11-03T15:46:01.240601Z"}},"outputs":[{"name":"stdout","text":"Model saved as impact_Score_xgb_regressor.pkl\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import pandas as pd\nimport pickle\nimport numpy as np\n\n# Load the model\nwith open(\"impact_Score_xgb_regressor.pkl\", 'rb') as file:\n    loaded_model = pickle.load(file)\n\n# Ensure y_test is a 1D NumPy array or pandas Series\nif isinstance(y_test, pd.DataFrame):\n    y_test = y_test.squeeze()  # Convert DataFrame to Series if it's a single column\n\n# Select a random row from the test set\nrandom_index = np.random.randint(0, len(X_test))  # Select random index\nrandom_input = X_test.iloc[random_index].values.reshape(1, -1)  # Use .iloc for correct indexing\nreal_output = y_test.iloc[random_index] if isinstance(y_test, pd.Series) else y_test[random_index]  # Access real output using .iloc\n\n# Predict the output using the loaded model\npredicted_output = loaded_model.predict(random_input)\n\nprint(f\"Real Output: {real_output:.4f}\")\nprint(f\"Predicted Output: {predicted_output[0]:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T16:56:25.453576Z","iopub.execute_input":"2024-11-03T16:56:25.453966Z","iopub.status.idle":"2024-11-03T16:56:25.476622Z","shell.execute_reply.started":"2024-11-03T16:56:25.453931Z","shell.execute_reply":"2024-11-03T16:56:25.475769Z"}},"outputs":[{"name":"stdout","text":"Real Output: 2.0000\nPredicted Output: 3.4117\n","output_type":"stream"}],"execution_count":91},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# BASE SCORE","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming 'df' is your DataFrame with all the columns\n# Define columns to exclude\ncolumns_to_exclude = [\n    'Impact_Score', 'CVE_ID', 'ASSIGNER', 'Description', \n    'Published_Date', 'Last_Modified_Date', \n    'Access_Vector', 'Access_Complexity', \n    'Configurations', 'Reference_Data',\n    'Year', 'Base_Score', 'Exploitability_Score', \n    'Confidentiality_Impact', 'Integrity_Impact', \n    'Availability_Impact'\n]\n\n# Separate the target variable\ny = df['Base_Score']  # Your target variable\n\n# Select all columns except the excluded ones\nX = df.drop(columns=columns_to_exclude)\n\n# Check shapes\nprint(X.shape)  # Should show (n_samples, n_features) where n_features should only include your embedding columns\nprint(y.shape)  # Should show (n_samples,)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T15:46:53.403042Z","iopub.execute_input":"2024-11-03T15:46:53.403677Z","iopub.status.idle":"2024-11-03T15:46:53.602651Z","shell.execute_reply.started":"2024-11-03T15:46:53.403637Z","shell.execute_reply":"2024-11-03T15:46:53.601576Z"}},"outputs":[{"name":"stdout","text":"(107087, 768)\n(107087,)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import pandas as pd\nimport xgboost as xgb\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom sklearn.model_selection import train_test_split\n\n# Load your dataset\n# X, y = ... (Load your features and target variable)\n\n# Split the dataset\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train XGBoost Regressor with GPU\nxgb_regressor_gpu = xgb.XGBRegressor(tree_method='gpu_hist', gpu_id=0)\nxgb_regressor_gpu.fit(X_train, y_train)\n\n# Predict and evaluate XGBoost\ny_pred_xgb_gpu = xgb_regressor_gpu.predict(X_test)\nmse_xgb_gpu = mean_squared_error(y_test, y_pred_xgb_gpu)\nmae_xgb_gpu = mean_absolute_error(y_test, y_pred_xgb_gpu)\nr2_xgb_gpu = r2_score(y_test, y_pred_xgb_gpu)\n\nprint(\"XGBoost GPU Metrics:\")\nprint(f\"MSE: {mse_xgb_gpu:.4f}, MAE: {mae_xgb_gpu:.4f}, R²: {r2_xgb_gpu:.4f}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T15:47:05.538133Z","iopub.execute_input":"2024-11-03T15:47:05.538522Z","iopub.status.idle":"2024-11-03T15:47:16.212444Z","shell.execute_reply.started":"2024-11-03T15:47:05.538477Z","shell.execute_reply":"2024-11-03T15:47:16.211474Z"}},"outputs":[{"name":"stdout","text":"XGBoost GPU Metrics:\nMSE: 1.4874, MAE: 0.9358, R²: 0.4681\n\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"import pandas as pd\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom sklearn.model_selection import train_test_split\n\n# Load your dataset\n# X, y = ... (Load your features and target variable)\n\n# Split the dataset\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train LightGBM Regressor with GPU\nlgb_regressor_gpu = lgb.LGBMRegressor(device='gpu')\nlgb_regressor_gpu.fit(X_train, y_train)\n\n# Predict and evaluate LightGBM\ny_pred_lgb_gpu = lgb_regressor_gpu.predict(X_test)\nmse_lgb_gpu = mean_squared_error(y_test, y_pred_lgb_gpu)\nmae_lgb_gpu = mean_absolute_error(y_test, y_pred_lgb_gpu)\nr2_lgb_gpu = r2_score(y_test, y_pred_lgb_gpu)\n\nprint(\"LightGBM GPU Metrics:\")\nprint(f\"MSE: {mse_lgb_gpu:.4f}, MAE: {mae_lgb_gpu:.4f}, R²: {r2_lgb_gpu:.4f}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T15:47:30.778301Z","iopub.execute_input":"2024-11-03T15:47:30.778712Z","iopub.status.idle":"2024-11-03T15:47:52.374190Z","shell.execute_reply.started":"2024-11-03T15:47:30.778662Z","shell.execute_reply":"2024-11-03T15:47:52.373091Z"}},"outputs":[{"name":"stdout","text":"[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 195840\n[LightGBM] [Info] Number of data points in the train set: 85669, number of used features: 768\n[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 768 dense feature groups (62.75 MB) transferred to GPU in 0.051842 secs. 0 sparse feature groups\n[LightGBM] [Info] Start training from score 6.439187\nLightGBM GPU Metrics:\nMSE: 1.5338, MAE: 0.9703, R²: 0.4515\n\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import pickle\n# Save the trained model using pickle\nmodel_filename = 'base_score_xgb_regressor.pkl'\nwith open(model_filename, 'wb') as file:\n    pickle.dump(xgb_regressor_gpu, file)\n\nprint(f\"Model saved as {model_filename}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T15:48:36.693577Z","iopub.execute_input":"2024-11-03T15:48:36.694312Z","iopub.status.idle":"2024-11-03T15:48:36.706706Z","shell.execute_reply.started":"2024-11-03T15:48:36.694273Z","shell.execute_reply":"2024-11-03T15:48:36.705806Z"}},"outputs":[{"name":"stdout","text":"Model saved as base_score_xgb_regressor.pkl\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"import pandas as pd\nimport pickle\nimport numpy as np\n\n# Load the model\nwith open(\"base_score_xgb_regressor.pkl\", 'rb') as file:\n    loaded_model = pickle.load(file)\n\n# Ensure y_test has a reset index if necessary\ny_test = y_test.reset_index(drop=True)\nX_test = X_test.reset_index(drop=True)\n\n# Select a random row from the test set\nrandom_index = np.random.randint(0, len(X_test))  # Select random index\nrandom_input = X_test.iloc[random_index].values.reshape(1, -1)  # Use .iloc and reshape for prediction\nreal_output = y_test.iloc[random_index]  # Access real output using .iloc\n\n# Predict the output using the loaded model\npredicted_output = loaded_model.predict(random_input)\n\n# Display the results\nprint(f\"Real Output: {real_output:.4f}\")\nprint(f\"Predicted Output: {predicted_output[0]:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T15:49:00.880482Z","iopub.execute_input":"2024-11-03T15:49:00.881362Z","iopub.status.idle":"2024-11-03T15:49:00.946295Z","shell.execute_reply.started":"2024-11-03T15:49:00.881322Z","shell.execute_reply":"2024-11-03T15:49:00.945347Z"}},"outputs":[{"name":"stdout","text":"Real Output: 7.4500\nPredicted Output: 7.8022\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Exploitability Score","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming 'df' is your DataFrame with all the columns\n# Define columns to exclude\ncolumns_to_exclude = [\n    'Impact_Score', 'CVE_ID', 'ASSIGNER', 'Description', \n    'Published_Date', 'Last_Modified_Date', \n    'Access_Vector', 'Access_Complexity', \n    'Configurations', 'Reference_Data',\n    'Year', 'Base_Score', 'Exploitability_Score', \n    'Confidentiality_Impact', 'Integrity_Impact', \n    'Availability_Impact'\n]\n\n# Separate the target variable\ny = df['Exploitability_Score']  # Your target variable\n\n# Select all columns except the excluded ones\nX = df.drop(columns=columns_to_exclude)\n\n# Check shapes\nprint(X.shape)  # Should show (n_samples, n_features) where n_features should only include your embedding columns\nprint(y.shape)  # Should show (n_samples,)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T15:49:54.973480Z","iopub.execute_input":"2024-11-03T15:49:54.974349Z","iopub.status.idle":"2024-11-03T15:49:55.172295Z","shell.execute_reply.started":"2024-11-03T15:49:54.974306Z","shell.execute_reply":"2024-11-03T15:49:55.171334Z"}},"outputs":[{"name":"stdout","text":"(107087, 768)\n(107087,)\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"import pandas as pd\nimport xgboost as xgb\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom sklearn.model_selection import train_test_split\n\n# Load your dataset\n# X, y = ... (Load your features and target variable)\n\n# Split the dataset\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train XGBoost Regressor with GPU\nxgb_regressor_gpu = xgb.XGBRegressor(tree_method='gpu_hist', gpu_id=0)\nxgb_regressor_gpu.fit(X_train, y_train)\n\n# Predict and evaluate XGBoost\ny_pred_xgb_gpu = xgb_regressor_gpu.predict(X_test)\nmse_xgb_gpu = mean_squared_error(y_test, y_pred_xgb_gpu)\nmae_xgb_gpu = mean_absolute_error(y_test, y_pred_xgb_gpu)\nr2_xgb_gpu = r2_score(y_test, y_pred_xgb_gpu)\n\nprint(\"XGBoost GPU Metrics:\")\nprint(f\"MSE: {mse_xgb_gpu:.4f}, MAE: {mae_xgb_gpu:.4f}, R²: {r2_xgb_gpu:.4f}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T15:50:26.459023Z","iopub.execute_input":"2024-11-03T15:50:26.460050Z","iopub.status.idle":"2024-11-03T15:50:36.918286Z","shell.execute_reply.started":"2024-11-03T15:50:26.460005Z","shell.execute_reply":"2024-11-03T15:50:36.917304Z"}},"outputs":[{"name":"stdout","text":"XGBoost GPU Metrics:\nMSE: 1.1731, MAE: 0.8116, R²: 0.4526\n\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"import pandas as pd\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom sklearn.model_selection import train_test_split\n\n# Load your dataset\n# X, y = ... (Load your features and target variable)\n\n# Split the dataset\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train LightGBM Regressor with GPU\nlgb_regressor_gpu = lgb.LGBMRegressor(device='gpu')\nlgb_regressor_gpu.fit(X_train, y_train)\n\n# Predict and evaluate LightGBM\ny_pred_lgb_gpu = lgb_regressor_gpu.predict(X_test)\nmse_lgb_gpu = mean_squared_error(y_test, y_pred_lgb_gpu)\nmae_lgb_gpu = mean_absolute_error(y_test, y_pred_lgb_gpu)\nr2_lgb_gpu = r2_score(y_test, y_pred_lgb_gpu)\n\nprint(\"LightGBM GPU Metrics:\")\nprint(f\"MSE: {mse_lgb_gpu:.4f}, MAE: {mae_lgb_gpu:.4f}, R²: {r2_lgb_gpu:.4f}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T15:50:41.503484Z","iopub.execute_input":"2024-11-03T15:50:41.503929Z","iopub.status.idle":"2024-11-03T15:51:02.658403Z","shell.execute_reply.started":"2024-11-03T15:50:41.503893Z","shell.execute_reply":"2024-11-03T15:51:02.657137Z"}},"outputs":[{"name":"stdout","text":"[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 195840\n[LightGBM] [Info] Number of data points in the train set: 85669, number of used features: 768\n[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 768 dense feature groups (62.75 MB) transferred to GPU in 0.049208 secs. 0 sparse feature groups\n[LightGBM] [Info] Start training from score 5.308553\nLightGBM GPU Metrics:\nMSE: 1.2120, MAE: 0.8494, R²: 0.4344\n\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# Save the trained model using pickle\nmodel_filename = 'exploitability_Score_xgb_regressor.pkl'\nwith open(model_filename, 'wb') as file:\n    pickle.dump(xgb_regressor_gpu, file)\n\nprint(f\"Model saved as {model_filename}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T15:51:44.894006Z","iopub.execute_input":"2024-11-03T15:51:44.894753Z","iopub.status.idle":"2024-11-03T15:51:44.912645Z","shell.execute_reply.started":"2024-11-03T15:51:44.894688Z","shell.execute_reply":"2024-11-03T15:51:44.911872Z"}},"outputs":[{"name":"stdout","text":"Model saved as exploitability_Score_xgb_regressor.pkl\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"import pandas as pd\nimport pickle\nimport numpy as np\n\n# Load the model\nwith open(\"exploitability_Score_xgb_regressor.pkl\", 'rb') as file:\n    loaded_model = pickle.load(file)\n\n# Reset the index of y_test to ensure it matches with X_test\ny_test = y_test.reset_index(drop=True)\nX_test = X_test.reset_index(drop=True)  # Reset X_test index to ensure alignment\n\n# Select a random row from the test set\nrandom_index = np.random.randint(0, len(X_test))  # Select random index\nrandom_input = X_test.iloc[random_index].values.reshape(1, -1)  # Use .iloc for positional indexing\nreal_output = y_test.iloc[random_index]  # Access real output using .iloc\n\n# Predict the output using the loaded model\npredicted_output = loaded_model.predict(random_input)\n\n# Display the results\nprint(f\"Real Output: {real_output:.4f}\")\nprint(f\"Predicted Output: {predicted_output[0]:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T15:53:25.068319Z","iopub.execute_input":"2024-11-03T15:53:25.069079Z","iopub.status.idle":"2024-11-03T15:53:25.135756Z","shell.execute_reply.started":"2024-11-03T15:53:25.069036Z","shell.execute_reply":"2024-11-03T15:53:25.135007Z"}},"outputs":[{"name":"stdout","text":"Real Output: 6.9500\nPredicted Output: 6.5360\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ACCESS COMPLEXITY","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming 'df' is your DataFrame with all the columns\n# Define columns to exclude\ncolumns_to_exclude = [\n    'Impact_Score', 'CVE_ID', 'ASSIGNER', 'Description', \n    'Published_Date', 'Last_Modified_Date', \n    'Access_Vector', 'Access_Complexity', \n    'Configurations', 'Reference_Data',\n    'Year', 'Base_Score', 'Exploitability_Score', \n    'Confidentiality_Impact', 'Integrity_Impact', \n    'Availability_Impact'\n]\n\n# Separate the target variable\ny = df['Access_Complexity']  # Your target variable\n\n# Select all columns except the excluded ones\nX = df.drop(columns=columns_to_exclude)\n\n# Check shapes\nprint(X.shape)  # Should show (n_samples, n_features) where n_features should only include your embedding columns\nprint(y.shape)  # Should show (n_samples,)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T16:25:21.987073Z","iopub.execute_input":"2024-11-03T16:25:21.988067Z","iopub.status.idle":"2024-11-03T16:25:22.189175Z","shell.execute_reply.started":"2024-11-03T16:25:21.988010Z","shell.execute_reply":"2024-11-03T16:25:22.188191Z"}},"outputs":[{"name":"stdout","text":"(107087, 768)\n(107087,)\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom cuml.ensemble import RandomForestClassifier as cuRF\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nimport pickle\nfrom cuml.metrics import accuracy_score, mean_squared_error, mean_absolute_error\nimport cupy as cp\n\n# Encode categorical labels into numeric values\nlabel_encoder = LabelEncoder()\ny_encoded = label_encoder.fit_transform(y)\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n\n# Convert to GPU arrays\nX_train_gpu = cp.asarray(X_train)\nX_test_gpu = cp.asarray(X_test)\ny_train_gpu = cp.asarray(y_train)\ny_test_gpu = cp.asarray(y_test)\n\n# Save the LabelEncoder as a pickle file\nwith open(\"Access_Complexity_label_encoder.pkl\", 'wb') as f:\n    pickle.dump(label_encoder, f)\n\n# Variables to store the best model and accuracy\nbest_model = None\nbest_accuracy = 0\nbest_model_name = \"\"\n\n# Function to train and evaluate a model\ndef train_and_evaluate(model, model_name):\n    global best_model, best_accuracy, best_model_name\n    \n    # Fit the model\n    model.fit(X_train_gpu if model_name != 'CatBoost' else X_train, \n              y_train_gpu if model_name != 'CatBoost' else y_train)\n\n    predictions = model.predict(X_test_gpu if model_name != 'CatBoost' else X_test)\n\n    # Calculate metrics\n    accuracy = accuracy_score(y_test_gpu, predictions) if model_name != 'CatBoost' else accuracy_score(y_test, predictions)\n    mse = mean_squared_error(y_test_gpu, predictions) if model_name != 'CatBoost' else mean_squared_error(y_test, predictions)\n    mae = mean_absolute_error(y_test_gpu, predictions) if model_name != 'CatBoost' else mean_absolute_error(y_test, predictions)\n\n    print(f\"{model_name} Accuracy: {accuracy:.4f}\")\n    print(f\"{model_name} Mean Squared Error: {mse:.4f}\")\n    print(f\"{model_name} Mean Absolute Error: {mae:.4f}\\n\")\n\n    # Update the best model if the current model has a higher accuracy\n    if accuracy > best_accuracy:\n        best_accuracy = accuracy\n        best_model = model\n        best_model_name = model_name\n\n# Initialize models with GPU support\nmodels = {\n    'XGBoost': XGBClassifier(device='cuda', eval_metric='mlogloss', random_state=42),\n    'CatBoost': CatBoostClassifier(task_type='GPU', verbose=0, random_state=42),\n    'Random Forest (cuML)': cuRF(n_estimators=100),\n}\n\n# Train and evaluate each model\nfor name, model in models.items():\n    train_and_evaluate(model, name)\n\n# Save the best model as a pickle file\nif best_model:\n    with open(f'Access_Complexity_best_{best_model_name.lower().replace(\" \", \"_\")}_model.pkl', 'wb') as f:\n        pickle.dump(best_model, f)\n    print(f\"Best model ({best_model_name}) saved with accuracy: {best_accuracy:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T16:25:55.064455Z","iopub.execute_input":"2024-11-03T16:25:55.065131Z","iopub.status.idle":"2024-11-03T16:26:30.680123Z","shell.execute_reply.started":"2024-11-03T16:25:55.065093Z","shell.execute_reply":"2024-11-03T16:26:30.679202Z"}},"outputs":[{"name":"stdout","text":"XGBoost Accuracy: 0.8501\nXGBoost Mean Squared Error: 0.1671\nXGBoost Mean Absolute Error: 0.1557\n\nCatBoost Accuracy: 0.8517\nCatBoost Mean Squared Error: 0.1670\nCatBoost Mean Absolute Error: 0.1545\n\nRandom Forest (cuML) Accuracy: 0.8327\nRandom Forest (cuML) Mean Squared Error: 0.1809\nRandom Forest (cuML) Mean Absolute Error: 0.1718\n\nBest model (CatBoost) saved with accuracy: 0.8517\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"import pickle\nimport numpy as np\n\n# Load the saved model and label encoder\nwith open(\"Access_Complexity_label_encoder.pkl\", 'rb') as f:\n    label_encoder = pickle.load(f)\n\nwith open(\"Access_Complexity_best_catboost_model.pkl\", 'rb') as f:\n    best_model = pickle.load(f)\n\n# Select a random sample from the test set\nrandom_index = np.random.randint(0, X_test.shape[0])\nrandom_sample = X_test[random_index:random_index + 1]\n\n# Predict the label for the sample (CatBoost requires data on CPU)\npredicted_label_encoded = best_model.predict(random_sample)\n\n# Convert the encoded prediction back to the original label\npredicted_label = label_encoder.inverse_transform(predicted_label_encoded.astype(int))\n\n# Get the actual label for the sample\nactual_label_encoded = y_test[random_index]\nactual_label = label_encoder.inverse_transform([actual_label_encoded])\n\n# Display the actual and predicted values\nprint(f\"Actual label: {actual_label[0]}\")\nprint(f\"Predicted label: {predicted_label[0]}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T16:26:52.418638Z","iopub.execute_input":"2024-11-03T16:26:52.419087Z","iopub.status.idle":"2024-11-03T16:26:52.479852Z","shell.execute_reply.started":"2024-11-03T16:26:52.419052Z","shell.execute_reply":"2024-11-03T16:26:52.478942Z"}},"outputs":[{"name":"stdout","text":"Actual label: MEDIUM\nPredicted label: MEDIUM\n","output_type":"stream"}],"execution_count":55},{"cell_type":"markdown","source":"# Access Vector","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming 'df' is your DataFrame with all the columns\n# Define columns to exclude\ncolumns_to_exclude = [\n    'Impact_Score', 'CVE_ID', 'ASSIGNER', 'Description', \n    'Published_Date', 'Last_Modified_Date', \n    'Access_Vector', 'Access_Complexity', \n    'Configurations', 'Reference_Data',\n    'Year', 'Base_Score', 'Exploitability_Score', \n    'Confidentiality_Impact', 'Integrity_Impact', \n    'Availability_Impact'\n]\n\n# Separate the target variable\ny = df['Access_Vector']  # Your target variable\n\n# Select all columns except the excluded ones\nX = df.drop(columns=columns_to_exclude)\n\n# Check shapes\nprint(X.shape)  # Should show (n_samples, n_features) where n_features should only include your embedding columns\nprint(y.shape)  # Should show (n_samples,)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T16:26:59.693978Z","iopub.execute_input":"2024-11-03T16:26:59.694361Z","iopub.status.idle":"2024-11-03T16:26:59.887920Z","shell.execute_reply.started":"2024-11-03T16:26:59.694317Z","shell.execute_reply":"2024-11-03T16:26:59.886888Z"}},"outputs":[{"name":"stdout","text":"(107087, 768)\n(107087,)\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom cuml.ensemble import RandomForestClassifier as cuRF\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nimport pickle\nfrom cuml.metrics import accuracy_score, mean_squared_error, mean_absolute_error\nimport cupy as cp\n\n# Encode categorical labels into numeric values\nlabel_encoder = LabelEncoder()\ny_encoded = label_encoder.fit_transform(y)\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n\n# Convert to GPU arrays\nX_train_gpu = cp.asarray(X_train)\nX_test_gpu = cp.asarray(X_test)\ny_train_gpu = cp.asarray(y_train)\ny_test_gpu = cp.asarray(y_test)\n\n# Save the LabelEncoder as a pickle file\nwith open(\"Access_Vector_label_encoder.pkl\", 'wb') as f:\n    pickle.dump(label_encoder, f)\n\n# Variables to store the best model and accuracy\nbest_model = None\nbest_accuracy = 0\nbest_model_name = \"\"\n\n# Function to train and evaluate a model\ndef train_and_evaluate(model, model_name):\n    global best_model, best_accuracy, best_model_name\n    \n    # Fit the model\n    model.fit(X_train_gpu if model_name != 'CatBoost' else X_train, \n              y_train_gpu if model_name != 'CatBoost' else y_train)\n\n    predictions = model.predict(X_test_gpu if model_name != 'CatBoost' else X_test)\n\n    # Calculate metrics\n    accuracy = accuracy_score(y_test_gpu, predictions) if model_name != 'CatBoost' else accuracy_score(y_test, predictions)\n    mse = mean_squared_error(y_test_gpu, predictions) if model_name != 'CatBoost' else mean_squared_error(y_test, predictions)\n    mae = mean_absolute_error(y_test_gpu, predictions) if model_name != 'CatBoost' else mean_absolute_error(y_test, predictions)\n\n    print(f\"{model_name} Accuracy: {accuracy:.4f}\")\n    print(f\"{model_name} Mean Squared Error: {mse:.4f}\")\n    print(f\"{model_name} Mean Absolute Error: {mae:.4f}\\n\")\n\n    # Update the best model if the current model has a higher accuracy\n    if accuracy > best_accuracy:\n        best_accuracy = accuracy\n        best_model = model\n        best_model_name = model_name\n\n# Initialize models with GPU support\nmodels = {\n    'XGBoost': XGBClassifier(device='cuda', eval_metric='mlogloss', random_state=42),\n    'CatBoost': CatBoostClassifier(task_type='GPU', verbose=0, random_state=42),\n    'Random Forest (cuML)': cuRF(n_estimators=100),\n}\n\n# Train and evaluate each model\nfor name, model in models.items():\n    train_and_evaluate(model, name)\n\n# Save the best model as a pickle file\nif best_model:\n    with open(f'accessVector_best_{best_model_name.lower().replace(\" \", \"_\")}_model.pkl', 'wb') as f:\n        pickle.dump(best_model, f)\n    print(f\"Best model ({best_model_name}) saved with accuracy: {best_accuracy:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T16:27:10.683937Z","iopub.execute_input":"2024-11-03T16:27:10.684335Z","iopub.status.idle":"2024-11-03T16:27:46.427720Z","shell.execute_reply.started":"2024-11-03T16:27:10.684300Z","shell.execute_reply":"2024-11-03T16:27:46.426638Z"}},"outputs":[{"name":"stdout","text":"XGBoost Accuracy: 0.9133\nXGBoost Mean Squared Error: 0.1291\nXGBoost Mean Absolute Error: 0.1008\n\nCatBoost Accuracy: 0.9153\nCatBoost Mean Squared Error: 0.1271\nCatBoost Mean Absolute Error: 0.0988\n\nRandom Forest (cuML) Accuracy: 0.8885\nRandom Forest (cuML) Mean Squared Error: 0.1629\nRandom Forest (cuML) Mean Absolute Error: 0.1286\n\nBest model (CatBoost) saved with accuracy: 0.9153\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"import pickle\nimport numpy as np\n\n# Load the saved model and label encoder\nwith open(\"Access_Vector_label_encoder.pkl\", 'rb') as f:\n    label_encoder = pickle.load(f)\n\nwith open(\"accessVector_best_catboost_model.pkl\", 'rb') as f:\n    best_model = pickle.load(f)\n\n# Select a random sample from the test set\nrandom_index = np.random.randint(0, X_test.shape[0])\nrandom_sample = X_test[random_index:random_index + 1]\n\n# Predict the label for the sample (CatBoost requires data on CPU)\npredicted_label_encoded = best_model.predict(random_sample)\n\n# Convert the encoded prediction back to the original label\npredicted_label = label_encoder.inverse_transform(predicted_label_encoded.astype(int))\n\n# Get the actual label for the sample\nactual_label_encoded = y_test[random_index]\nactual_label = label_encoder.inverse_transform([actual_label_encoded])\n\n# Display the actual and predicted values\nprint(f\"Actual label: {actual_label[0]}\")\nprint(f\"Predicted label: {predicted_label[0]}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T16:28:26.843101Z","iopub.execute_input":"2024-11-03T16:28:26.843822Z","iopub.status.idle":"2024-11-03T16:28:27.144797Z","shell.execute_reply.started":"2024-11-03T16:28:26.843778Z","shell.execute_reply":"2024-11-03T16:28:27.143710Z"}},"outputs":[{"name":"stdout","text":"Actual label: LOCAL\nPredicted label: LOCAL\n","output_type":"stream"}],"execution_count":60},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Availability Impact","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming 'df' is your DataFrame with all the columns\n# Define columns to exclude\ncolumns_to_exclude = [\n    'Impact_Score', 'CVE_ID', 'ASSIGNER', 'Description', \n    'Published_Date', 'Last_Modified_Date', \n    'Access_Vector', 'Access_Complexity', \n    'Configurations', 'Reference_Data',\n    'Year', 'Base_Score', 'Exploitability_Score', \n    'Confidentiality_Impact', 'Integrity_Impact', \n    'Availability_Impact'\n]\n\n# Separate the target variable\ny = df['Availability_Impact']  # Your target variable\n\n# Select all columns except the excluded ones\nX = df.drop(columns=columns_to_exclude)\n\n# Check shapes\nprint(X.shape)  # Should show (n_samples, n_features) where n_features should only include your embedding columns\nprint(y.shape)  # Should show (n_samples,)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T16:29:28.293398Z","iopub.execute_input":"2024-11-03T16:29:28.294411Z","iopub.status.idle":"2024-11-03T16:29:28.496451Z","shell.execute_reply.started":"2024-11-03T16:29:28.294354Z","shell.execute_reply":"2024-11-03T16:29:28.495511Z"}},"outputs":[{"name":"stdout","text":"(107087, 768)\n(107087,)\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom cuml.ensemble import RandomForestClassifier as cuRF\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nimport pickle\nfrom cuml.metrics import accuracy_score, mean_squared_error, mean_absolute_error\nimport cupy as cp\n\n# Encode categorical labels into numeric values\nlabel_encoder = LabelEncoder()\ny_encoded = label_encoder.fit_transform(y)\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n\n# Convert to GPU arrays\nX_train_gpu = cp.asarray(X_train)\nX_test_gpu = cp.asarray(X_test)\ny_train_gpu = cp.asarray(y_train)\ny_test_gpu = cp.asarray(y_test)\n\n# Save the LabelEncoder as a pickle file\nwith open(\"Availability_Impact_label_encoder.pkl\", 'wb') as f:\n    pickle.dump(label_encoder, f)\n\n# Variables to store the best model and accuracy\nbest_model = None\nbest_accuracy = 0\nbest_model_name = \"\"\n\n# Function to train and evaluate a model\ndef train_and_evaluate(model, model_name):\n    global best_model, best_accuracy, best_model_name\n    \n    # Fit the model\n    model.fit(X_train_gpu if model_name != 'CatBoost' else X_train, \n              y_train_gpu if model_name != 'CatBoost' else y_train)\n\n    predictions = model.predict(X_test_gpu if model_name != 'CatBoost' else X_test)\n\n    # Calculate metrics\n    accuracy = accuracy_score(y_test_gpu, predictions) if model_name != 'CatBoost' else accuracy_score(y_test, predictions)\n    mse = mean_squared_error(y_test_gpu, predictions) if model_name != 'CatBoost' else mean_squared_error(y_test, predictions)\n    mae = mean_absolute_error(y_test_gpu, predictions) if model_name != 'CatBoost' else mean_absolute_error(y_test, predictions)\n\n    print(f\"{model_name} Accuracy: {accuracy:.4f}\")\n    print(f\"{model_name} Mean Squared Error: {mse:.4f}\")\n    print(f\"{model_name} Mean Absolute Error: {mae:.4f}\\n\")\n\n    # Update the best model if the current model has a higher accuracy\n    if accuracy > best_accuracy:\n        best_accuracy = accuracy\n        best_model = model\n        best_model_name = model_name\n\n# Initialize models with GPU support\nmodels = {\n    'XGBoost': XGBClassifier(device='cuda', eval_metric='mlogloss', random_state=42),\n    'CatBoost': CatBoostClassifier(task_type='GPU', verbose=0, random_state=42),\n    'Random Forest (cuML)': cuRF(n_estimators=100),\n}\n\n# Train and evaluate each model\nfor name, model in models.items():\n    train_and_evaluate(model, name)\n\n# Save the best model as a pickle file\nif best_model:\n    with open(f'Availability_Impact_best_{best_model_name.lower().replace(\" \", \"_\")}_model.pkl', 'wb') as f:\n        pickle.dump(best_model, f)\n    print(f\"Best model ({best_model_name}) saved with accuracy: {best_accuracy:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T16:30:32.094436Z","iopub.execute_input":"2024-11-03T16:30:32.094837Z","iopub.status.idle":"2024-11-03T16:31:09.866268Z","shell.execute_reply.started":"2024-11-03T16:30:32.094797Z","shell.execute_reply":"2024-11-03T16:31:09.865269Z"}},"outputs":[{"name":"stdout","text":"XGBoost Accuracy: 0.8713\nXGBoost Mean Squared Error: 0.4592\nXGBoost Mean Absolute Error: 0.2389\n\nCatBoost Accuracy: 0.8729\nCatBoost Mean Squared Error: 0.4511\nCatBoost Mean Absolute Error: 0.2351\n\nRandom Forest (cuML) Accuracy: 0.8474\nRandom Forest (cuML) Mean Squared Error: 0.5488\nRandom Forest (cuML) Mean Absolute Error: 0.2847\n\nBest model (CatBoost) saved with accuracy: 0.8729\n","output_type":"stream"}],"execution_count":62},{"cell_type":"code","source":"import pickle\nimport numpy as np\n\n# Load the saved model and label encoder\nwith open(\"Availability_Impact_label_encoder.pkl\", 'rb') as f:\n    label_encoder = pickle.load(f)\n\nwith open(\"Availability_Impact_best_catboost_model.pkl\", 'rb') as f:\n    best_model = pickle.load(f)\n\n# Select a random sample from the test set\nrandom_index = np.random.randint(0, X_test.shape[0])\nrandom_sample = X_test[random_index:random_index + 1]\n\n# Predict the label for the sample (CatBoost requires data on CPU)\npredicted_label_encoded = best_model.predict(random_sample)\n\n# Convert the encoded prediction back to the original label\npredicted_label = label_encoder.inverse_transform(predicted_label_encoded.astype(int))\n\n# Get the actual label for the sample\nactual_label_encoded = y_test[random_index]\nactual_label = label_encoder.inverse_transform([actual_label_encoded])\n\n# Display the actual and predicted values\nprint(f\"Actual label: {actual_label[0]}\")\nprint(f\"Predicted label: {predicted_label[0]}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T16:33:49.988151Z","iopub.execute_input":"2024-11-03T16:33:49.988527Z","iopub.status.idle":"2024-11-03T16:33:50.045473Z","shell.execute_reply.started":"2024-11-03T16:33:49.988491Z","shell.execute_reply":"2024-11-03T16:33:50.044541Z"}},"outputs":[{"name":"stdout","text":"Actual label: HIGH\nPredicted label: HIGH\n","output_type":"stream"}],"execution_count":66},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Confidentiality Impact","metadata":{}},{"cell_type":"code","source":"\nimport pandas as pd\n\n# Assuming 'df' is your DataFrame with all the columns\n# Define columns to exclude\ncolumns_to_exclude = [\n    'Impact_Score', 'CVE_ID', 'ASSIGNER', 'Description', \n    'Published_Date', 'Last_Modified_Date', \n    'Access_Vector', 'Access_Complexity', \n    'Configurations', 'Reference_Data',\n    'Year', 'Base_Score', 'Exploitability_Score', \n    'Confidentiality_Impact', 'Integrity_Impact', \n    'Availability_Impact'\n]\n\n# Separate the target variable\ny = df['Confidentiality_Impact']  # Your target variable\n\n# Select all columns except the excluded ones\nX = df.drop(columns=columns_to_exclude)\n\n# Check shapes\nprint(X.shape)  # Should show (n_samples, n_features) where n_features should only include your embedding columns\nprint(y.shape)  # Should show (n_samples,)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T16:36:10.543656Z","iopub.execute_input":"2024-11-03T16:36:10.544093Z","iopub.status.idle":"2024-11-03T16:36:10.739744Z","shell.execute_reply.started":"2024-11-03T16:36:10.544054Z","shell.execute_reply":"2024-11-03T16:36:10.738707Z"}},"outputs":[{"name":"stdout","text":"(107087, 768)\n(107087,)\n","output_type":"stream"}],"execution_count":68},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom cuml.ensemble import RandomForestClassifier as cuRF\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nimport pickle\nfrom cuml.metrics import accuracy_score, mean_squared_error, mean_absolute_error\nimport cupy as cp\n\n# Encode categorical labels into numeric values\nlabel_encoder = LabelEncoder()\ny_encoded = label_encoder.fit_transform(y)\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n\n# Convert to GPU arrays\nX_train_gpu = cp.asarray(X_train)\nX_test_gpu = cp.asarray(X_test)\ny_train_gpu = cp.asarray(y_train)\ny_test_gpu = cp.asarray(y_test)\n\n# Save the LabelEncoder as a pickle file\nwith open(\"Confidentiality_Impact_label_encoder.pkl\", 'wb') as f:\n    pickle.dump(label_encoder, f)\n\n# Variables to store the best model and accuracy\nbest_model = None\nbest_accuracy = 0\nbest_model_name = \"\"\n\n# Function to train and evaluate a model\ndef train_and_evaluate(model, model_name):\n    global best_model, best_accuracy, best_model_name\n    \n    # Fit the model\n    model.fit(X_train_gpu if model_name != 'CatBoost' else X_train, \n              y_train_gpu if model_name != 'CatBoost' else y_train)\n\n    predictions = model.predict(X_test_gpu if model_name != 'CatBoost' else X_test)\n\n    # Calculate metrics\n    accuracy = accuracy_score(y_test_gpu, predictions) if model_name != 'CatBoost' else accuracy_score(y_test, predictions)\n    mse = mean_squared_error(y_test_gpu, predictions) if model_name != 'CatBoost' else mean_squared_error(y_test, predictions)\n    mae = mean_absolute_error(y_test_gpu, predictions) if model_name != 'CatBoost' else mean_absolute_error(y_test, predictions)\n\n    print(f\"{model_name} Accuracy: {accuracy:.4f}\")\n    print(f\"{model_name} Mean Squared Error: {mse:.4f}\")\n    print(f\"{model_name} Mean Absolute Error: {mae:.4f}\\n\")\n\n    # Update the best model if the current model has a higher accuracy\n    if accuracy > best_accuracy:\n        best_accuracy = accuracy\n        best_model = model\n        best_model_name = model_name\n\n# Initialize models with GPU support\nmodels = {\n    'XGBoost': XGBClassifier(device='cuda', eval_metric='mlogloss', random_state=42),\n    'CatBoost': CatBoostClassifier(task_type='GPU', verbose=0, random_state=42),\n    'Random Forest (cuML)': cuRF(n_estimators=100),\n}\n\n# Train and evaluate each model\nfor name, model in models.items():\n    train_and_evaluate(model, name)\n\n# Save the best model as a pickle file\nif best_model:\n    with open(f'Confidentiality_Impact_best_{best_model_name.lower().replace(\" \", \"_\")}_model.pkl', 'wb') as f:\n        pickle.dump(best_model, f)\n    print(f\"Best model ({best_model_name}) saved with accuracy: {best_accuracy:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T16:37:06.083840Z","iopub.execute_input":"2024-11-03T16:37:06.084502Z","iopub.status.idle":"2024-11-03T16:37:43.910922Z","shell.execute_reply.started":"2024-11-03T16:37:06.084461Z","shell.execute_reply":"2024-11-03T16:37:43.909930Z"}},"outputs":[{"name":"stdout","text":"XGBoost Accuracy: 0.8372\nXGBoost Mean Squared Error: 0.4241\nXGBoost Mean Absolute Error: 0.2499\n\nCatBoost Accuracy: 0.8388\nCatBoost Mean Squared Error: 0.4199\nCatBoost Mean Absolute Error: 0.2475\n\nRandom Forest (cuML) Accuracy: 0.7983\nRandom Forest (cuML) Mean Squared Error: 0.5488\nRandom Forest (cuML) Mean Absolute Error: 0.3174\n\nBest model (CatBoost) saved with accuracy: 0.8388\n","output_type":"stream"}],"execution_count":69},{"cell_type":"code","source":"import pickle\nimport numpy as np\n\n# Load the saved model and label encoder\nwith open(\"Confidentiality_Impact_label_encoder.pkl\", 'rb') as f:\n    label_encoder = pickle.load(f)\n\nwith open(\"Confidentiality_Impact_best_catboost_model.pkl\", 'rb') as f:\n    best_model = pickle.load(f)\n\n# Select a random sample from the test set\nrandom_index = np.random.randint(0, X_test.shape[0])\nrandom_sample = X_test[random_index:random_index + 1]\n\n# Predict the label for the sample (CatBoost requires data on CPU)\npredicted_label_encoded = best_model.predict(random_sample)\n\n# Convert the encoded prediction back to the original label\npredicted_label = label_encoder.inverse_transform(predicted_label_encoded.astype(int))\n\n# Get the actual label for the sample\nactual_label_encoded = y_test[random_index]\nactual_label = label_encoder.inverse_transform([actual_label_encoded])\n\n# Display the actual and predicted values\nprint(f\"Actual label: {actual_label[0]}\")\nprint(f\"Predicted label: {predicted_label[0]}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T16:38:43.133881Z","iopub.execute_input":"2024-11-03T16:38:43.134293Z","iopub.status.idle":"2024-11-03T16:38:43.193302Z","shell.execute_reply.started":"2024-11-03T16:38:43.134237Z","shell.execute_reply":"2024-11-03T16:38:43.192388Z"}},"outputs":[{"name":"stdout","text":"Actual label: HIGH\nPredicted label: HIGH\n","output_type":"stream"}],"execution_count":71},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Integrity Impact","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming 'df' is your DataFrame with all the columns\n# Define columns to exclude\ncolumns_to_exclude = [\n    'Impact_Score', 'CVE_ID', 'ASSIGNER', 'Description', \n    'Published_Date', 'Last_Modified_Date', \n    'Access_Vector', 'Access_Complexity', \n    'Configurations', 'Reference_Data',\n    'Year', 'Base_Score', 'Exploitability_Score', \n    'Confidentiality_Impact', 'Integrity_Impact', \n    'Availability_Impact'\n]\n\n# Separate the target variable\ny = df['Integrity_Impact']  # Your target variable\n\n# Select all columns except the excluded ones\nX = df.drop(columns=columns_to_exclude)\n\n# Check shapes\nprint(X.shape)  # Should show (n_samples, n_features) where n_features should only include your embedding columns\nprint(y.shape)  # Should show (n_samples,)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T16:39:52.093599Z","iopub.execute_input":"2024-11-03T16:39:52.094519Z","iopub.status.idle":"2024-11-03T16:39:52.289645Z","shell.execute_reply.started":"2024-11-03T16:39:52.094475Z","shell.execute_reply":"2024-11-03T16:39:52.288592Z"}},"outputs":[{"name":"stdout","text":"(107087, 768)\n(107087,)\n","output_type":"stream"}],"execution_count":72},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom cuml.ensemble import RandomForestClassifier as cuRF\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nimport pickle\nfrom cuml.metrics import accuracy_score, mean_squared_error, mean_absolute_error\nimport cupy as cp\n\n# Encode categorical labels into numeric values\nlabel_encoder = LabelEncoder()\ny_encoded = label_encoder.fit_transform(y)\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n\n# Convert to GPU arrays\nX_train_gpu = cp.asarray(X_train)\nX_test_gpu = cp.asarray(X_test)\ny_train_gpu = cp.asarray(y_train)\ny_test_gpu = cp.asarray(y_test)\n\n# Save the LabelEncoder as a pickle file\nwith open(\"Integrity_Impactt_label_encoder.pkl\", 'wb') as f:\n    pickle.dump(label_encoder, f)\n\n# Variables to store the best model and accuracy\nbest_model = None\nbest_accuracy = 0\nbest_model_name = \"\"\n\n# Function to train and evaluate a model\ndef train_and_evaluate(model, model_name):\n    global best_model, best_accuracy, best_model_name\n    \n    # Fit the model\n    model.fit(X_train_gpu if model_name != 'CatBoost' else X_train, \n              y_train_gpu if model_name != 'CatBoost' else y_train)\n\n    predictions = model.predict(X_test_gpu if model_name != 'CatBoost' else X_test)\n\n    # Calculate metrics\n    accuracy = accuracy_score(y_test_gpu, predictions) if model_name != 'CatBoost' else accuracy_score(y_test, predictions)\n    mse = mean_squared_error(y_test_gpu, predictions) if model_name != 'CatBoost' else mean_squared_error(y_test, predictions)\n    mae = mean_absolute_error(y_test_gpu, predictions) if model_name != 'CatBoost' else mean_absolute_error(y_test, predictions)\n\n    print(f\"{model_name} Accuracy: {accuracy:.4f}\")\n    print(f\"{model_name} Mean Squared Error: {mse:.4f}\")\n    print(f\"{model_name} Mean Absolute Error: {mae:.4f}\\n\")\n\n    # Update the best model if the current model has a higher accuracy\n    if accuracy > best_accuracy:\n        best_accuracy = accuracy\n        best_model = model\n        best_model_name = model_name\n\n# Initialize models with GPU support\nmodels = {\n    'XGBoost': XGBClassifier(device='cuda', eval_metric='mlogloss', random_state=42),\n    'CatBoost': CatBoostClassifier(task_type='GPU', verbose=0, random_state=42),\n    'Random Forest (cuML)': cuRF(n_estimators=100),\n}\n\n# Train and evaluate each model\nfor name, model in models.items():\n    train_and_evaluate(model, name)\n\n# Save the best model as a pickle file\nif best_model:\n    with open(f'Integrity_Impact_best_{best_model_name.lower().replace(\" \", \"_\")}_model.pkl', 'wb') as f:\n        pickle.dump(best_model, f)\n    print(f\"Best model ({best_model_name}) saved with accuracy: {best_accuracy:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T16:40:57.494125Z","iopub.execute_input":"2024-11-03T16:40:57.494621Z","iopub.status.idle":"2024-11-03T16:41:36.409340Z","shell.execute_reply.started":"2024-11-03T16:40:57.494583Z","shell.execute_reply":"2024-11-03T16:41:36.408327Z"}},"outputs":[{"name":"stdout","text":"XGBoost Accuracy: 0.8418\nXGBoost Mean Squared Error: 0.4629\nXGBoost Mean Absolute Error: 0.2598\n\nCatBoost Accuracy: 0.8434\nCatBoost Mean Squared Error: 0.4506\nCatBoost Mean Absolute Error: 0.2546\n\nRandom Forest (cuML) Accuracy: 0.8056\nRandom Forest (cuML) Mean Squared Error: 0.5835\nRandom Forest (cuML) Mean Absolute Error: 0.3241\n\nBest model (CatBoost) saved with accuracy: 0.8434\n","output_type":"stream"}],"execution_count":73},{"cell_type":"code","source":"import pickle\nimport numpy as np\n\n# Load the saved model and label encoder\nwith open(\"Integrity_Impactt_label_encoder.pkl\", 'rb') as f:\n    label_encoder = pickle.load(f)\n\nwith open(\"Integrity_Impact_best_catboost_model.pkl\", 'rb') as f:\n    best_model = pickle.load(f)\n\n# Select a random sample from the test set\nrandom_index = np.random.randint(0, X_test.shape[0])\nrandom_sample = X_test[random_index:random_index + 1]\n\n# Predict the label for the sample (CatBoost requires data on CPU)\npredicted_label_encoded = best_model.predict(random_sample)\n\n# Convert the encoded prediction back to the original label\npredicted_label = label_encoder.inverse_transform(predicted_label_encoded.astype(int))\n\n# Get the actual label for the sample\nactual_label_encoded = y_test[random_index]\nactual_label = label_encoder.inverse_transform([actual_label_encoded])\n\n# Display the actual and predicted values\nprint(f\"Actual label: {actual_label[0]}\")\nprint(f\"Predicted label: {predicted_label[0]}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T16:42:14.758497Z","iopub.execute_input":"2024-11-03T16:42:14.759450Z","iopub.status.idle":"2024-11-03T16:42:14.819804Z","shell.execute_reply.started":"2024-11-03T16:42:14.759406Z","shell.execute_reply":"2024-11-03T16:42:14.818777Z"}},"outputs":[{"name":"stdout","text":"Actual label: NONE\nPredicted label: NONE\n","output_type":"stream"}],"execution_count":75},{"cell_type":"markdown","source":"# Predicting Vulnerability Impact Metrics","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport pickle\nimport numpy as np\nimport warnings\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\n# Suppress warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Load your DataFrame\n# df = pd.read_csv('your_dataset.csv')  # Uncomment and specify your DataFrame source\n\n# Define columns to exclude\ncolumns_to_exclude = [\n    'Impact_Score', 'CVE_ID', 'ASSIGNER', 'Description', \n    'Published_Date', 'Last_Modified_Date', \n    'Access_Vector', 'Access_Complexity', \n    'Configurations', 'Reference_Data',\n    'Year', 'Base_Score', 'Exploitability_Score', \n    'Confidentiality_Impact', 'Integrity_Impact', \n    'Availability_Impact'\n]\n\n# List of target variables\ntarget_variables = [\n    'Impact_Score',\n    'Base_Score',\n    'Exploitability_Score',\n    'Access_Complexity',\n    'Access_Vector',\n    'Availability_Impact',\n    'Confidentiality_Impact',\n    'Integrity_Impact'\n]\n\n# Function to split dataset and return train-test splits\ndef train_test_split_for_target(target):\n    # Separate the target variable\n    y = df[target]\n    \n    # Select all columns except the excluded ones\n    X = df.drop(columns=columns_to_exclude)\n    \n    # If the target is categorical, encode it\n    if target in ['Access_Complexity', 'Access_Vector', 'Availability_Impact', 'Confidentiality_Impact', 'Integrity_Impact']:\n        label_encoder = LabelEncoder()\n        y = label_encoder.fit_transform(y)\n        return train_test_split(X, y, test_size=0.2, random_state=42), label_encoder  # Return encoder for later use\n    else:\n        return train_test_split(X, y, test_size=0.2, random_state=42), None\n\n# Load regression models\nregression_models = {\n    \"Impact_Score\": \"impact_Score_xgb_regressor.pkl\",\n    \"Base_Score\": \"base_score_xgb_regressor.pkl\",\n    \"Exploitability_Score\": \"exploitability_Score_xgb_regressor.pkl\"\n}\n\n# Load classification models and label encoders\nclassification_models = {\n    \"Access_Complexity\": (\"Access_Complexity_best_catboost_model.pkl\", \"Access_Complexity_label_encoder.pkl\"),\n    \"Access_Vector\": (\"accessVector_best_catboost_model.pkl\", \"Access_Vector_label_encoder.pkl\"),\n    \"Availability_Impact\": (\"Availability_Impact_best_catboost_model.pkl\", \"Availability_Impact_label_encoder.pkl\"),\n    \"Confidentiality_Impact\": (\"Confidentiality_Impact_best_catboost_model.pkl\", \"Confidentiality_Impact_label_encoder.pkl\"),\n    \"Integrity_Impact\": (\"Integrity_Impact_best_catboost_model.pkl\", \"Integrity_Impactt_label_encoder.pkl\"),\n}\n\n# Initialize dictionaries to hold actual and predicted values\nactual_outputs = {}\npredicted_outputs = {}\n\n# Loop through all target variables to get train-test splits and make predictions\nfor target in target_variables:\n    (X_train, X_test, y_train, y_test), label_encoder = train_test_split_for_target(target)\n\n    # Reset index of y_test and X_test if necessary\n    y_test = pd.Series(y_test).reset_index(drop=True)\n    X_test = pd.DataFrame(X_test).reset_index(drop=True)\n\n    # Select a random row from the test set\n    random_index = np.random.randint(0, len(X_test))\n    random_input = X_test.iloc[random_index].values.reshape(1, -1)\n\n    # Predict for regression models\n    if target in regression_models.keys():\n        model_file = regression_models[target]\n        with open(model_file, 'rb') as file:\n            loaded_model = pickle.load(file)\n        real_output = y_test.iloc[random_index]\n        predicted_output = loaded_model.predict(random_input)\n        actual_outputs[target] = real_output\n        predicted_outputs[target] = predicted_output[0]\n\n    # Predict for classification models\n    elif target in classification_models.keys():\n        model_file, encoder_file = classification_models[target]\n        with open(encoder_file, 'rb') as f:\n            label_encoder = pickle.load(f)\n        with open(model_file, 'rb') as f:\n            best_model = pickle.load(f)\n\n        predicted_label_encoded = best_model.predict(random_input)\n        predicted_label = label_encoder.inverse_transform(predicted_label_encoded.astype(int))\n        actual_label_encoded = y_test.iloc[random_index]\n        actual_label = label_encoder.inverse_transform([actual_label_encoded])\n\n        actual_outputs[target] = actual_label[0]\n        predicted_outputs[target] = predicted_label[0]\n\n# Display actual and predicted values for all outputs\nprint(\"Actual Outputs:\")\nfor key, value in actual_outputs.items():\n    print(f\"{key}: {value}\")\n\nprint(\"\\nPredicted Outputs:\")\nfor key, value in predicted_outputs.items():\n    print(f\"{key}: {value}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T17:40:58.538945Z","iopub.execute_input":"2024-11-03T17:40:58.539668Z","iopub.status.idle":"2024-11-03T17:41:04.762641Z","shell.execute_reply.started":"2024-11-03T17:40:58.539630Z","shell.execute_reply":"2024-11-03T17:41:04.761594Z"}},"outputs":[{"name":"stdout","text":"Actual Outputs:\nImpact_Score: 3.6\nBase_Score: 8.65\nExploitability_Score: 5.4\nAccess_Complexity: MEDIUM\nAccess_Vector: NETWORK\nAvailability_Impact: NONE\nConfidentiality_Impact: HIGH\nIntegrity_Impact: NONE\n\nPredicted Outputs:\nImpact_Score: 3.181267499923706\nBase_Score: 7.35125207901001\nExploitability_Score: 5.7252655029296875\nAccess_Complexity: LOW\nAccess_Vector: NETWORK\nAvailability_Impact: NONE\nConfidentiality_Impact: HIGH\nIntegrity_Impact: NONE\n","output_type":"stream"}],"execution_count":123}]}